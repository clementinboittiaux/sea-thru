{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4def9ef-03d9-4298-8033-66cfd17c03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import torch\n",
    "import rawpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "def load_image(data_path, image_name):\n",
    "    image_file = data_path / 'Raw' / image_name\n",
    "    depth_file = data_path / 'depthMaps' / f'depth{os.path.splitext(image_name)[0]}.tif'\n",
    "    depth = np.array(Image.open(depth_file), dtype=np.float64)\n",
    "    raw = rawpy.imread(str(image_file))\n",
    "    rgb = raw.postprocess()\n",
    "    rgb = cv2.resize(rgb / 255, depth.shape[::-1])\n",
    "    return rgb, depth\n",
    "\n",
    "\n",
    "def plot_image(image, **kwargs):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image, **kwargs)\n",
    "\n",
    "\n",
    "def save_image(image, image_name):\n",
    "    im = image - image.min()\n",
    "    im = im / im.max()\n",
    "    im = im * 255\n",
    "    Image.fromarray(im.astype(np.uint8)).save(image_name)\n",
    "\n",
    "\n",
    "def stretch_histogram(image, clip_percentile=0.0):\n",
    "    im = image.copy()\n",
    "    for channel in range(3):\n",
    "        im[:, :, channel] = im[:, :, channel].clip(\n",
    "            np.percentile(im[:, :, channel], clip_percentile),\n",
    "            np.percentile(im[:, :, channel], 100 - clip_percentile)\n",
    "        )\n",
    "        im[:, :, channel] = (im[:, :, channel] - im[:, :, channel].mean()) / im[:, :, channel].std()\n",
    "        im[:, :, channel] -= im[:, :, channel].min()\n",
    "        im[:, :, channel] /= im[:, :, channel].max()\n",
    "    return im\n",
    "\n",
    "\n",
    "def compute_omega(I, depth, min_depth_percentile=1, max_depth_percentile=99):\n",
    "    \n",
    "    depth_ranges = np.linspace(\n",
    "        np.percentile(depth, min_depth_percentile),\n",
    "        np.percentile(depth, max_depth_percentile),\n",
    "        11\n",
    "    )\n",
    "    \n",
    "    omega = []\n",
    "    for min_depth, max_depth in zip(depth_ranges[:-1], depth_ranges[1:]):\n",
    "        args_depth_in_range = np.argwhere((depth >= min_depth) & (depth < max_depth))\n",
    "        I_in_range = I[args_depth_in_range[:, 0], args_depth_in_range[:, 1]]\n",
    "        mean_I_in_range = I_in_range.mean(axis=1)\n",
    "        omega_range_mask = mean_I_in_range < np.percentile(mean_I_in_range, 1)\n",
    "        omega.append(args_depth_in_range[omega_range_mask])\n",
    "    return np.vstack(omega)\n",
    "\n",
    "\n",
    "def compute_backscatter(I, depth, z):\n",
    "    \n",
    "    print('Computing backscatter')\n",
    "    \n",
    "    omega = compute_omega(I, depth)\n",
    "    \n",
    "    B_hat = I[omega[:, 0], omega[:, 1]]\n",
    "    z = z[omega[:, 0], omega[:, 1]]\n",
    "    \n",
    "    B_inf_init = B_hat.mean(axis=0).tolist()\n",
    "    beta_B_init = [2.5, 2.5, 2.5]\n",
    "    J_prime_init = [0.0, 0.0, 0.0]\n",
    "    beta_D_prime_init = [0.0, 0.0, 0.0]\n",
    "    \n",
    "    def residuals(x):\n",
    "        B_inf, beta_B, J_prime, beta_D_prime = np.array_split(x, 4)\n",
    "        return (B_hat - B_inf * (1 - np.exp(-beta_B * z)) - J_prime * np.exp(-beta_D_prime * z)).flatten()\n",
    "    \n",
    "    return least_squares(\n",
    "        residuals,\n",
    "        B_inf_init + beta_B_init + J_prime_init + beta_D_prime_init,\n",
    "        bounds=([0] * 12, [1, 1, 1, 5, 5, 5] * 2),\n",
    "        jac='3-point',\n",
    "        verbose=2\n",
    "    ).x\n",
    "\n",
    "\n",
    "def LSAC(D, depth, sigma=0.1, eps=0.01, f=2):\n",
    "    \n",
    "    print('Computing LSAC')\n",
    "    \n",
    "    D = torch.tensor(D).cuda()\n",
    "    \n",
    "    Ne = np.zeros(depth.shape)\n",
    "    Ne_vertical_mask = np.abs(depth[1:] - depth[:-1]) < eps\n",
    "    Ne_horizontal_mask = np.abs(depth[:, 1:] - depth[:, :-1]) < eps\n",
    "    Ne[1:] += Ne_vertical_mask\n",
    "    Ne[:-1] += Ne_vertical_mask\n",
    "    Ne[:, 1:] += Ne_horizontal_mask\n",
    "    Ne[:, :-1] += Ne_horizontal_mask\n",
    "    Ne = Ne.clip(min=1e-16)\n",
    "    Ne = torch.tensor(Ne[..., np.newaxis]).double().cuda()\n",
    "    Ne_vertical_mask = torch.tensor(Ne_vertical_mask[..., np.newaxis]).double().cuda()\n",
    "    Ne_horizontal_mask = torch.tensor(Ne_horizontal_mask[..., np.newaxis]).double().cuda()\n",
    "    \n",
    "    a = torch.zeros(D.shape, dtype=torch.float64).cuda()\n",
    "    \n",
    "    p = torch.tensor(1 / (np.square(sigma * max(depth.shape)) + 1), dtype=torch.float64).cuda()\n",
    "    \n",
    "    for i in tqdm.tqdm(range(1000)):\n",
    "        \n",
    "        a_prime = torch.zeros(a.shape, dtype=torch.float64).cuda()\n",
    "        a_prime[1:] += a[:-1] * Ne_vertical_mask\n",
    "        a_prime[:-1] += a[1:] * Ne_vertical_mask\n",
    "        a_prime[:, 1:] += a[:, :-1] * Ne_horizontal_mask\n",
    "        a_prime[:, :-1] += a[:, 1:] * Ne_horizontal_mask\n",
    "        a_prime /= Ne\n",
    "        a = D * p + a_prime * (1 - p)\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            save_image(a.cpu().numpy(), f'lsac/{i:06d}.png')\n",
    "    \n",
    "    E_hat = f * a\n",
    "    \n",
    "    return E_hat.cpu().numpy()\n",
    "\n",
    "\n",
    "def beta_D(a, b, c, d, z):\n",
    "    return a * torch.exp(b * z) + c * torch.exp(d * z)\n",
    "\n",
    "\n",
    "def init_beta_D_from_beta_D_prime(beta_D_prime, z):\n",
    "    \n",
    "    print('Initialize beta_D coefficients from beta_D_prime')\n",
    "    \n",
    "    beta_D_prime = torch.tensor(beta_D_prime).cuda()\n",
    "    z = torch.tensor(z).cuda()\n",
    "    \n",
    "    def residuals(x):\n",
    "        a, b, c, d = torch.tensor(x).cuda().tensor_split(4)\n",
    "        return (beta_D_prime - beta_D(a, b, c, d, z)).flatten().cpu().numpy()\n",
    "\n",
    "    return least_squares(\n",
    "        residuals,\n",
    "        [0] * 12,\n",
    "        bounds=([0, -np.inf] * 6, [np.inf, 0] * 6),\n",
    "        jac='3-point',\n",
    "        verbose=2\n",
    "    ).x\n",
    "\n",
    "\n",
    "def compute_beta_D(D, depth, z, beta_D_prime):\n",
    "    \n",
    "    E_hat = LSAC(D, depth)\n",
    "    \n",
    "    beta_D_init = init_beta_D_from_beta_D_prime(beta_D_prime, z)\n",
    "    \n",
    "    E_hat = torch.tensor(E_hat).cuda()\n",
    "    z = torch.tensor(z).cuda()\n",
    "    \n",
    "    print('Estimate beta_D coefficients')\n",
    "    \n",
    "    def residuals(x):\n",
    "        a, b, c, d = torch.tensor(x).cuda().tensor_split(4)\n",
    "        return (z + torch.log(E_hat) / beta_D(a, b, c, d, z)).flatten().cpu().numpy()\n",
    "    \n",
    "    return least_squares(\n",
    "        residuals,\n",
    "        beta_D_init,\n",
    "        bounds=([0, -np.inf] * 6, [np.inf, 0] * 6),\n",
    "        jac='3-point',\n",
    "        verbose=2\n",
    "    ).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5670f0-2fe8-4bac-aced-1d39f418709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing backscatter\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         2.7214e+02                                    1.30e+03    \n",
      "       1              3         2.5598e+02      1.62e+01       1.28e-02       4.09e+01    \n",
      "       2              4         2.4876e+02      7.22e+00       3.43e-01       6.40e+01    \n",
      "       3              5         2.4825e+02      5.06e-01       1.06e-02       5.62e+01    \n",
      "       4              6         2.3241e+02      1.58e+01       6.74e-01       3.14e+02    \n",
      "       5              7         2.3165e+02      7.59e-01       2.91e-03       4.43e+01    \n",
      "       6              9         2.2399e+02      7.66e+00       2.60e-01       8.15e+01    \n",
      "       7             10         2.2372e+02      2.66e-01       4.30e-03       7.27e+01    \n",
      "       8             11         2.1043e+02      1.33e+01       4.96e-01       4.41e+02    \n",
      "       9             13         2.0840e+02      2.02e+00       4.96e-03       5.31e+01    \n",
      "      10             14         2.0092e+02      7.48e+00       2.13e-01       1.10e+02    \n",
      "      11             15         2.0052e+02      4.00e-01       3.81e-03       1.09e+02    \n",
      "      12             16         2.0032e+02      2.00e-01       1.77e-03       3.64e+01    \n",
      "      13             17         1.9541e+02      4.91e+00       4.09e-01       8.65e+02    \n",
      "      14             18         1.8799e+02      7.41e+00       1.09e-02       5.48e+01    \n",
      "      15             19         1.8581e+02      2.18e+00       2.89e-01       9.21e+02    \n",
      "      16             20         1.7870e+02      7.12e+00       1.22e-02       4.42e+01    \n",
      "      17             21         1.7565e+02      3.04e+00       1.21e-01       2.93e+02    \n",
      "      18             22         1.7451e+02      1.15e+00       1.59e-02       2.64e+02    \n",
      "      19             23         1.7414e+02      3.64e-01       3.09e-03       3.06e+01    \n",
      "      20             25         1.7267e+02      1.48e+00       5.37e-02       6.20e+01    \n",
      "      21             26         1.7064e+02      2.03e+00       1.00e-01       3.59e+02    \n",
      "      22             27         1.7029e+02      3.51e-01       3.35e-03       5.06e+01    \n",
      "      23             29         1.6926e+02      1.03e+00       4.25e-02       6.90e+01    \n",
      "      24             30         1.6776e+02      1.51e+00       8.02e-02       3.16e+02    \n",
      "      25             31         1.6757e+02      1.89e-01       3.48e-03       3.10e+02    \n",
      "      26             32         1.6740e+02      1.70e-01       2.57e-03       5.23e+01    \n",
      "      27             34         1.6669e+02      7.07e-01       3.62e-02       6.67e+01    \n",
      "      28             35         1.6562e+02      1.07e+00       6.92e-02       2.81e+02    \n",
      "      29             36         1.6551e+02      1.05e-01       2.15e-03       4.37e+01    \n",
      "      30             37         1.6525e+02      2.60e-01       1.27e-01       1.09e+03    \n",
      "      31             38         1.6390e+02      1.35e+00       6.09e-03       7.06e+01    \n",
      "      32             39         1.6353e+02      3.77e-01       2.40e-02       3.27e+01    \n",
      "      33             40         1.6291e+02      6.12e-01       4.99e-02       1.55e+02    \n",
      "      34             41         1.6237e+02      5.48e-01       5.31e-02       2.24e+02    \n",
      "      35             42         1.6210e+02      2.68e-01       4.10e-02       1.97e+02    \n",
      "      36             43         1.6186e+02      2.32e-01       4.25e-02       1.77e+02    \n",
      "      37             44         1.6158e+02      2.80e-01       5.88e-02       1.71e+02    \n",
      "      38             45         1.6155e+02      3.09e-02       3.20e-03       1.66e+02    \n",
      "      39             46         1.6128e+02      2.71e-01       7.94e-02       1.61e+02    \n",
      "      40             47         1.6104e+02      2.45e-01       9.48e-02       1.46e+02    \n",
      "      41             48         1.6080e+02      2.37e-01       1.07e-01       1.32e+02    \n",
      "      42             49         1.6058e+02      2.16e-01       1.19e-01       1.14e+02    \n",
      "      43             50         1.6040e+02      1.81e-01       1.20e-01       9.28e+01    \n",
      "      44             51         1.6023e+02      1.71e-01       1.33e-01       7.65e+01    \n",
      "      45             52         1.6009e+02      1.46e-01       6.14e-02       6.13e+01    \n",
      "      46             53         1.5997e+02      1.15e-01       1.78e-01       3.72e+01    \n",
      "      47             54         1.5997e+02      3.59e-03       8.62e-03       3.57e+01    \n",
      "      48             55         1.5987e+02      9.76e-02       1.75e-01       2.49e+01    \n",
      "      49             56         1.5987e+02      4.60e-03       9.33e-03       2.29e+01    \n",
      "      50             57         1.5982e+02      4.88e-02       2.25e-01       7.91e+00    \n",
      "      51             58         1.5981e+02      3.08e-03       1.06e-02       6.84e+00    \n",
      "      52             59         1.5980e+02      1.57e-02       2.53e-01       1.38e+00    \n",
      "      53             60         1.5980e+02      2.15e-04       1.84e-02       1.12e+00    \n",
      "      54             61         1.5980e+02      1.67e-03       4.67e-01       1.61e-01    \n",
      "      55             62         1.5980e+02      1.47e-04       3.30e-03       4.20e-03    \n",
      "      56             63         1.5980e+02      8.02e-07       6.15e-01       4.11e-05    \n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 63, initial cost 2.7214e+02, final cost 1.5980e+02, first-order optimality 4.11e-05.\n",
      "Computing LSAC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:00<00:00, 16.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize beta_D coefficients from beta_D_prime\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         1.2404e+07                                    1.62e+07    \n",
      "       1              2         1.2403e+07      6.48e+02       2.83e-05       1.62e+07    \n",
      "       2              3         1.2402e+07      1.30e+03       5.66e-05       1.62e+07    \n",
      "       3              4         1.2399e+07      2.59e+03       1.13e-04       1.62e+07    \n",
      "       4              5         1.2394e+07      5.18e+03       2.26e-04       1.62e+07    \n",
      "       5              6         1.2384e+07      1.04e+04       4.53e-04       1.62e+07    \n",
      "       6              7         1.2363e+07      2.07e+04       9.05e-04       1.62e+07    \n",
      "       7              8         1.2322e+07      4.14e+04       1.81e-03       1.61e+07    \n",
      "       8              9         1.2239e+07      8.25e+04       3.62e-03       1.61e+07    \n",
      "       9             10         1.2075e+07      1.64e+05       7.24e-03       1.60e+07    \n",
      "      10             11         1.1750e+07      3.25e+05       1.45e-02       1.58e+07    \n",
      "      11             12         1.1113e+07      6.37e+05       2.90e-02       1.53e+07    \n",
      "      12             13         9.8919e+06      1.22e+06       5.79e-02       1.45e+07    \n",
      "      13             14         7.6634e+06      2.23e+06       1.16e-01       1.27e+07    \n",
      "      14             15         4.0585e+06      3.60e+06       2.32e-01       9.27e+06    \n",
      "      15             16         2.5733e+05      3.80e+06       4.63e-01       2.33e+06    \n",
      "      16             17         4.2246e+02      2.57e+05       9.27e-01       7.21e+04    \n",
      "      17             18         1.7677e+02      2.46e+02       4.82e-03       2.66e-07    \n",
      "      18             19         1.7677e+02      3.73e-07       6.20e-12       4.97e-05    \n",
      "Both `ftol` and `xtol` termination conditions are satisfied.\n",
      "Function evaluations 19, initial cost 1.2404e+07, final cost 1.7677e+02, first-order optimality 4.97e-05.\n",
      "Estimate beta_D coefficients\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         3.3918e+27                                    1.68e+33    \n",
      "       1              2         8.3235e+18      3.39e+27       2.85e-06       2.27e+24    \n",
      "       2              3         1.0481e+18      7.28e+18       5.19e-06       1.51e+23    \n",
      "       3              4         2.1302e+17      8.35e+17       1.72e-05       1.79e+22    \n",
      "       4              5         5.6461e+16      1.57e+17       1.68e-05       2.34e+21    \n",
      "       5              6         1.4336e+16      4.21e+16       3.41e-05       2.96e+20    \n",
      "       6              7         3.6012e+15      1.07e+16       6.85e-05       3.71e+19    \n",
      "       7              8         9.0437e+14      2.70e+15       1.37e-04       4.64e+18    \n",
      "       8              9         2.2931e+14      6.75e+14       2.74e-04       5.80e+17    \n",
      "       9             10         6.0479e+13      1.69e+14       5.49e-04       7.25e+16    \n",
      "      10             11         1.1066e+13      4.94e+13       7.23e-01       7.90e+15    \n",
      "      11             12         4.0857e+12      6.98e+12       1.67e-03       9.83e+14    \n",
      "      12             13         1.6554e+12      2.43e+12       4.06e-03       2.08e+14    \n",
      "      13             14         4.6190e+11      1.19e+12       9.52e-03       2.54e+13    \n",
      "      14             15         1.2698e+11      3.35e+11       1.82e-02       4.26e+12    \n",
      "      15             16         2.9150e+10      9.78e+10       1.06e+00       6.51e+11    \n",
      "      16             17         6.4458e+09      2.27e+10       1.42e+00       8.21e+10    \n",
      "      17             18         1.6212e+09      4.82e+09       2.83e+00       2.98e+10    \n",
      "      18             19         4.1084e+08      1.21e+09       2.67e+00       2.72e+10    \n",
      "      19             20         1.0722e+08      3.04e+08       2.74e+00       8.43e+10    \n",
      "      20             21         2.4932e+07      8.23e+07       2.83e+00       7.05e+09    \n",
      "      21             22         1.0519e+07      1.44e+07       4.71e+00       9.30e+06    \n",
      "      22             23         8.0574e+06      2.46e+06       5.68e+00       1.52e+06    \n",
      "      23             24         7.7745e+06      2.83e+05       5.67e+00       7.21e+05    \n",
      "      24             26         7.6307e+06      1.44e+05       1.63e+00       3.77e+05    \n",
      "      25             27         7.5284e+06      1.02e+05       1.63e+00       3.54e+04    \n",
      "      26             28         7.5067e+06      2.17e+04       3.24e+00       5.77e+05    \n",
      "      27             29         7.4875e+06      1.92e+04       4.54e-02       3.76e+04    \n",
      "      28             31         7.4852e+06      2.36e+03       4.33e-01       1.26e+04    \n",
      "      29             33         7.4848e+06      3.91e+02       2.30e-01       5.35e+04    \n",
      "      30             35         7.4844e+06      3.55e+02       7.46e-02       5.82e+03    \n",
      "      31             36         7.4842e+06      2.20e+02       1.70e-01       2.50e+04    \n",
      "      32             37         7.4841e+06      1.21e+02       3.94e-01       8.88e+04    \n",
      "      33             38         7.4835e+06      5.32e+02       1.20e-01       1.26e+03    \n",
      "      34             39         7.4834e+06      1.16e+02       1.09e-01       5.69e+03    \n",
      "      35             40         7.4832e+06      2.37e+02       4.12e-01       4.38e+04    \n",
      "      36             41         7.4827e+06      4.46e+02       5.03e-01       1.98e+04    \n",
      "      37             42         7.4822e+06      5.39e+02       1.07e+00       5.19e+04    \n",
      "      38             44         7.4818e+06      3.84e+02       6.04e-01       4.70e+03    \n",
      "      39             46         7.4818e+06      6.16e+01       1.12e-01       2.00e+04    \n",
      "      40             48         7.4817e+06      7.08e+01       6.47e-02       9.85e+03    \n",
      "      41             49         7.4816e+06      8.07e+01       1.43e-01       3.88e+04    \n",
      "      42             50         7.4814e+06      2.11e+02       1.82e-01       3.18e+04    \n",
      "      43             51         7.4814e+06      5.48e+00       4.33e-01       7.39e+04    \n",
      "      44             52         7.4808e+06      5.55e+02       1.35e-01       5.42e+02    \n",
      "      45             53         7.4807e+06      9.96e+01       1.08e-01       3.23e+03    \n",
      "      46             54         7.4805e+06      1.95e+02       3.26e-01       2.69e+04    \n",
      "      47             55         7.4802e+06      3.93e+02       1.06e+00       6.58e+04    \n",
      "      48             56         7.4794e+06      7.24e+02       1.01e+00       5.92e+03    \n",
      "      49             57         7.4791e+06      3.20e+02       1.10e+00       4.68e+04    \n",
      "      50             58         7.4784e+06      6.79e+02       2.54e+00       1.91e+04    \n",
      "      51             59         7.4782e+06      2.16e+02       4.46e+00       3.08e+04    \n",
      "      52             60         7.4774e+06      8.29e+02       5.00e-01       1.22e+04    \n",
      "      53             61         7.4772e+06      2.17e+02       8.71e-01       3.16e+03    \n",
      "      54             62         7.4768e+06      3.55e+02       1.74e+00       1.28e+04    \n",
      "      55             63         7.4763e+06      5.09e+02       3.49e+00       2.94e+04    \n",
      "      56             64         7.4762e+06      5.99e+01       7.33e+00       7.73e+04    \n",
      "      57             65         7.4755e+06      7.33e+02       1.74e+00       3.39e+03    \n",
      "      58             66         7.4752e+06      2.71e+02       3.49e+00       1.91e+04    \n",
      "      59             67         7.4749e+06      3.85e+02       1.07e+01       2.93e+04    \n",
      "      60             68         7.4747e+06      2.03e+02       1.39e+01       3.28e+04    \n",
      "      61             69         7.4743e+06      3.27e+02       1.39e+01       1.88e+04    \n",
      "      62             70         7.4742e+06      1.12e+02       2.79e+01       3.43e+04    \n",
      "      63             71         7.4739e+06      3.37e+02       2.79e+01       1.98e+04    \n",
      "      64             72         7.4737e+06      1.25e+02       5.57e+01       3.42e+04    \n",
      "      65             73         7.4734e+06      3.17e+02       5.57e+01       1.86e+04    \n",
      "      66             74         7.4733e+06      1.28e+02       1.11e+02       3.03e+04    \n",
      "      67             75         7.4731e+06      2.36e+02       1.11e+02       2.58e+04    \n",
      "      68             76         7.4729e+06      2.06e+02       1.11e+02       8.47e+03    \n",
      "      69             77         7.4728e+06      5.66e+01       2.23e+02       2.18e+04    \n",
      "      70             78         7.4726e+06      2.19e+02       2.23e+02       9.44e+03    \n",
      "      71             79         7.4725e+06      4.63e+01       4.46e+02       1.87e+04    \n",
      "      72             80         7.4723e+06      1.99e+02       4.46e+02       9.51e+03    \n",
      "      73             81         7.4723e+06      3.91e+01       8.91e+02       1.85e+04    \n",
      "      74             82         7.4721e+06      1.70e+02       8.91e+02       9.00e+03    \n",
      "      75             83         7.4721e+06      2.99e+01       1.78e+03       1.80e+04    \n",
      "      76             84         7.4720e+06      1.13e+02       4.46e+02       4.16e+02    \n",
      "      77             85         7.4720e+06      3.18e+01       8.91e+02       2.56e+03    \n",
      "      78             86         7.4719e+06      4.32e+01       1.78e+03       6.53e+03    \n",
      "      79             87         7.4719e+06      4.65e+01       1.78e+03       4.13e+03    \n",
      "      80             88         7.4718e+06      3.54e+01       3.57e+03       1.02e+04    \n",
      "      81             89         7.4718e+06      5.87e+01       3.57e+03       5.76e+03    \n",
      "      82             90         7.4718e+06      1.86e+01       7.13e+03       1.33e+04    \n",
      "      83             91         7.4717e+06      6.84e+01       7.13e+03       6.96e+03    \n",
      "      84             93         7.4717e+06      2.45e+01       3.57e+03       1.23e+03    \n",
      "      85             94         7.4716e+06      1.90e+01       7.13e+03       4.04e+03    \n",
      "      86             95         7.4716e+06      1.41e+01       1.43e+04       9.66e+03    \n",
      "      87             96         7.4716e+06      3.52e+01       1.43e+04       5.59e+03    \n",
      "      88             98         7.4716e+06      1.45e+01       7.13e+03       1.03e+03    \n",
      "      89             99         7.4716e+06      1.10e+01       1.43e+04       3.35e+03    \n",
      "      90             100        7.4716e+06      5.84e+00       2.85e+04       8.37e+03    \n",
      "      91             101        7.4715e+06      2.10e+01       2.85e+04       5.05e+03    \n",
      "      92             103        7.4715e+06      9.18e+00       1.43e+04       9.54e+02    \n",
      "      93             104        7.4715e+06      5.06e+00       2.85e+04       3.05e+03    \n",
      "      94             105        7.4715e+06      5.61e+00       2.85e+04       2.25e+03    \n",
      "      95             107        7.4715e+06      2.78e+00       1.43e+04       4.85e+02    \n",
      "      96             108        7.4715e+06      2.57e+00       2.85e+04       1.57e+03    \n",
      "      97             109        7.4715e+06      5.03e-01       5.71e+04       4.48e+03    \n",
      "      98             110        7.4715e+06      4.30e+00       1.43e+04       2.29e+02    \n",
      "      99             111        7.4715e+06      8.20e-01       2.85e+04       8.07e+02    \n",
      "      100            113        7.4715e+06      4.49e-01       1.43e+04       1.96e+02    \n",
      "      101            114        7.4715e+06      4.06e-01       2.85e+04       6.43e+02    \n",
      "      102            115        7.4715e+06      2.62e-01       2.85e+04       5.61e+02    \n",
      "      103            116        7.4715e+06      7.12e-02       2.85e+04       4.94e+02    \n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 116, initial cost 3.3918e+27, final cost 7.4715e+06, first-order optimality 4.94e+02.\n"
     ]
    }
   ],
   "source": [
    "I, depth = load_image(Path('dataset/D1P1/'), 'T_S03136.ARW')\n",
    "z = depth[..., np.newaxis].repeat(3, 2)\n",
    "\n",
    "B_inf, beta_B, J_prime, beta_D_prime = np.array_split(compute_backscatter(I, depth, z), 4)\n",
    "\n",
    "B = B_inf * (1 - np.exp(-beta_B * z))\n",
    "D = I - B\n",
    "D = D - D.min()\n",
    "\n",
    "a, b, c, d = np.array_split(compute_beta_D(D, depth, z, beta_D_prime), 4)\n",
    "\n",
    "save_image(stretch_histogram(D, 0), 'test/D.png')\n",
    "save_image(D, 'test/RawD.png')\n",
    "save_image(stretch_histogram(I, 0), 'test/I.png')\n",
    "save_image(I, 'test/RawI.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f76f41-6e2c-4c2b-af4e-2a8e94880e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = D * np.exp((a * np.exp(b * z) + c * np.exp(d * z)) * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac20f2e-03d4-4dc0-a876-20769d5e907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clementin/anaconda3/envs/seathru/lib/python3.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "save_image(stretch_histogram(J, 0), 'test/J.png')\n",
    "save_image(J, 'test/RawJ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdae98c3-91ae-4037-ba7e-5e208121fdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa81a5a8-c254-4396-b315-10f24ab2a584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J[:,:,1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0d5b5df-c30e-4aac-bb6f-0f8cfa4480a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp((a[1] * np.exp(b[1] * z[:, :, 1]) + c[1] * np.exp(d[1] * z[:, :, 1])) * z[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f63ef347-4791-4fe2-8d1d-bcae0a137436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.50521316e+22, -3.48689371e+22, -3.46868778e+22, ...,\n",
       "        -5.06344779e+16, -5.07442845e+16, -5.08543291e+16],\n",
       "       [-3.53403244e+22, -3.51559842e+22, -3.49722469e+22, ...,\n",
       "        -5.08382959e+16, -5.09485444e+16, -5.10591629e+16],\n",
       "       [-3.56310694e+22, -3.54450309e+22, -3.52597829e+22, ...,\n",
       "        -5.10429343e+16, -5.11537578e+16, -5.12646904e+16],\n",
       "       ...,\n",
       "       [-2.87816716e+31, -2.82858740e+31, -2.78945629e+31, ...,\n",
       "        -4.49519145e+16, -4.47879972e+16, -4.46249066e+16],\n",
       "       [-2.82760138e+31, -2.79353540e+31, -2.77662816e+31, ...,\n",
       "        -4.47901789e+16, -4.46268514e+16, -4.44642335e+16],\n",
       "       [-2.79763483e+31, -2.78068852e+31, -2.76385902e+31, ...,\n",
       "        -4.46289108e+16, -4.44663994e+16, -4.43042526e+16]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1] * np.exp(b[1] * z[:, :, 1]) + c[1] * np.exp(d[1] * z[:, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4bcf28-76f2-4f6f-a800-6eea6cfb8b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.82217624,  43.01049489, -15.05133899])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b42a94-cc31-4cc5-a392-cce404d43754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.87509113, -2.63189396, 10.19396058])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb58172c-8408-4ead-a7cb-842806799c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49742838,  1.17939979, -0.72181494])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31ff3a43-f085-4476-b18c-84194f3ef209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clementin/anaconda3/envs/seathru/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f397861c350>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(J[:, :, 1] / J[:, :, 1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d1067-5307-4df0-ac0a-2d6d205e281d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
